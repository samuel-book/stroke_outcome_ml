{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost models informed by feature selection analysis (using all data)\n",
    "\n",
    "Population to train IVT decision model\n",
    "Just ischaemic.\n",
    "No anticolgalents\n",
    "No thrombectomy patients.\n",
    "\n",
    "SAVE FILE PATIENTS TREATED PER SCENARIO\n",
    "\n",
    "### Plain English summary\n",
    "\n",
    "Use a model equivalent to the one trained in notebook 040 (but for this one use all data to train the model, and no test set) to calculate the multiclass mRS distributions (individual mRS + cumulative distributions + weighted mRS) for all of the patients in the population with/without thrombolysis (Assume no-one on AFIb anticoagulant would receive thrombolysis - so remove these from the population and report the number removed).\n",
    "\n",
    "The model includes 7 features: [\"prior_disability\", \"stroke_severity\", \"stroke_team\", \"age\", \"onset-to-thrombolysis-time\", \"any_afib_diagnosis\", \"precise_onset_known\"]\n",
    "\n",
    "How would outcomes compare using:\n",
    "1. actual decision made\n",
    "1. benchmark\n",
    "1. 'best outcome'\n",
    "\n",
    "### Model and data\n",
    "XGBoost\\\n",
    "7 features: [\"prior_disability\", \"stroke_severity\", \"stroke_team\", \"age\", \"onset-to-thrombolysis-time\", \"any_afib_diagnosis\", \"precise_onset_known\"]\\\n",
    "All data (not use kfolds)\n",
    "\n",
    "### Aims\n",
    "\n",
    "### Observations\n",
    "\n",
    "\n",
    "#### Further work\n",
    "\n",
    "#### Resources\n",
    "pip install plotly\n",
    "pip install dash"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn warnings off to keep notebook tidy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import plotly.express as px\n",
    "\n",
    "import scipy\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import json\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pickle\n",
    "import shap\n",
    "\n",
    "from os.path import exists\n",
    "\n",
    "import math\n",
    "\n",
    "import importlib\n",
    "# Import local package\n",
    "#from utils import waterfall\n",
    "## Force package to be reloaded\n",
    "#importlib.reload(waterfall);\n",
    "\n",
    "# Need for cm subplots?\n",
    "#from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "#from matplotlib.colors import LogNorm\n",
    "#from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "#pip install category_encoders\n",
    "#import category_encoders as ce\n",
    "\n",
    "#import dash_core_components as dcc\n",
    "#from dash import dcc\n",
    "#import plotly.express as px\n",
    "#import plotly.subplots as sp\n",
    "#from plotly.offline import plot\n",
    "#from plotly.subplots import make_subplots\n",
    "\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the time duration to run notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For those patients that do not get thrombolysis, the onset to thrombolysis time to calculate their outcome had they been given thrombolysis\n",
    "ott_default = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the features for the model for disability discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_mrs = [\"prior_disability\", \"stroke_severity\", \"stroke_team\", \n",
    "                     \"age\", \"onset_to_thrombolysis_time\", \"any_afib_diagnosis\", \n",
    "                     \"precise_onset_known\", \"discharge_disability\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the features for the model for treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_treatment = [\"prior_disability\", \"stroke_severity\", \n",
    "                     \"age\", \"arrival_to_scan_time\", \"precise_onset_known\", \n",
    "                     \"onset_to_arrival_time\",\"onset_during_sleep\", \n",
    "                     \"stroke_team\", \"S2Thrombolysis\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get union of both sets of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_set = list(set.union(set(selected_features_mrs), \n",
    "                                       set(selected_features_treatment)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up paths and filenames\n",
    "\n",
    "For consistency, the folders end with \"/\" and the text for filenames include no trailing \"_\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Paths:\n",
    "    '''Singleton object for storing paths to data and database.'''\n",
    "    image_save_path: str = './saved_images'\n",
    "    model_save_path: str = './saved_models'\n",
    "    data_save_path: str = './saved_data'\n",
    "    data_read_path: str = '../data_processing/output'\n",
    "    model_text: str = 'xgb_all_data_multiclass_outcome'\n",
    "    notebook: str = '210_'\n",
    "\n",
    "paths = Paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create output folders if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = paths.image_save_path\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "        \n",
    "path = paths.model_save_path\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "path = paths.data_save_path\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "Data has previously been split into 5 stratified k-fold splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in training set, restrict to chosen features & store\n",
    "filename = os.path.join(paths.data_read_path, '02_reformatted_data_ml.csv')\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create new feature \"S2Thrombolysis\" from the surrogate \"scan_to_thrombolysis_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"S2Thrombolysis\"] = data[\"scan_to_thrombolysis_time\"] > -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create series \"onset_to_thrombolysis_time_all_treated\" for all patients.\n",
    "\n",
    "To be used for the scenarios when patients that are not treated in the dataset are treated in the scenario (they are without a scan to treatment time, use the average for the hospital they attended)\n",
    "\n",
    "First calculate the average scan_to_thrombolysis_time for those patients that got treated (per hospital) as then use this for those that do not get treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stroke_team\n",
       "Addenbrooke's Hospital          20.0\n",
       "Basildon University Hospital    34.0\n",
       "Blackpool Victoria Hospital     37.0\n",
       "Bradford and Airedale SU        47.0\n",
       "Bronglais Hospital              39.5\n",
       "                                ... \n",
       "Worthing Hospital               38.0\n",
       "Wycombe General Hospital        29.0\n",
       "Yeovil District Hospital        37.0\n",
       "York Hospital                   29.0\n",
       "Ysbyty Gwynedd                  44.0\n",
       "Name: scan_to_thrombolysis_time, Length: 118, dtype: float64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median scan to treatment for the treated patients (per hosptial)\n",
    "mask_treatment = data[\"S2Thrombolysis\"] == 1\n",
    "median_scan_to_needle_time = (\n",
    "    data[mask_treatment].groupby([\"stroke_team\"])[\"scan_to_thrombolysis_time\"].median())\n",
    "\n",
    "median_scan_to_needle_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new series \"onset_to_thrombolysis_time_all_treated\" which takes the dataset value for those patients that are treated in the dataset. For those patients that are not treated in the dataset add the mdeian hospital scan to treatment time to their individual onset to scan times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          368.5\n",
       "1          272.0\n",
       "2          115.0\n",
       "3          569.5\n",
       "4          179.0\n",
       "           ...  \n",
       "168342     307.5\n",
       "168343    1291.0\n",
       "168344     368.0\n",
       "168345     182.0\n",
       "168346     130.0\n",
       "Name: onset_to_thrombolysis_time, Length: 168347, dtype: float64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify patients not recieve treatment in thte dataset\n",
    "mask_not_treated = data[\"S2Thrombolysis\"] == 0\n",
    "\n",
    "# Take a deep copy of the onset to thrombolysis time. This will remain unchanged \n",
    "# for those patients that recieve treatment in the dataset\n",
    "onset_to_thrombolysis_time_all_treated = data[\"onset_to_thrombolysis_time\"].copy(deep=True)\n",
    "\n",
    "# For those patients not recieve treatment in the dataset, use the median scan to treatment of their attended hosptial\n",
    "onset_to_scan_time = data[\"onset_to_arrival_time\"] + data[\"arrival_to_scan_time\"]\n",
    "onset_to_thrombolysis_time_all_treated[mask_not_treated] = (\n",
    "    onset_to_scan_time[mask_not_treated] + \n",
    "    median_scan_to_needle_time[data[\"stroke_team\"]].values[mask_not_treated])\n",
    "\n",
    "onset_to_thrombolysis_time_all_treated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select features to use in  both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[selected_features_set]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot the categorical features\n",
    "\n",
    "Convert some categorical features to one hot encoded features.\n",
    "\n",
    "Define a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_feature_to_one_hot(df, feature_name, prefix):\n",
    "    \"\"\"\n",
    "    df [dataframe]: training or test dataset\n",
    "    feature_name [str]: feature to convert to ont hot encoding\n",
    "    prefix [str]: string to use on new feature\n",
    "    \"\"\"\n",
    "\n",
    "    # One hot encode a feature\n",
    "    df_feature = pd.get_dummies(\n",
    "        df[feature_name], prefix = prefix)\n",
    "    df = pd.concat([df, df_feature], axis=1)\n",
    "    df.drop(feature_name, axis=1, inplace=True)\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up two lists for the one hot encoding. \n",
    "\n",
    "A list of the feature names that are categorical and to be converted using one hot encoding.\n",
    "A list of the prefixes to use for these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_one_hot = [\"stroke_team\", \"weekday\"]\n",
    "list_prefix = [\"team\", \"weekday\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each feature in the list, for each train and test dataset, convert to one hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, prefix in zip(features_to_one_hot, list_prefix):\n",
    "    if feature in selected_features_set:\n",
    "        data = convert_feature_to_one_hot(data, feature, prefix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature names with one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_ohe = list(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the team names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_stroke_team_features = [col for col in feature_names_ohe if col.startswith('team')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the feature names to use in the model (remove \"stroke_team\" and add in all the one hot encoded feature names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the column name \"stroke_team\" with the ohe column names\n",
    "selected_features_mrs.remove(\"stroke_team\")\n",
    "selected_features_mrs = selected_features_mrs + ohe_stroke_team_features\n",
    "\n",
    "# replace the column name \"stroke_team\" with the ohe column names\n",
    "selected_features_treatment.remove(\"stroke_team\")\n",
    "selected_features_treatment = selected_features_treatment + ohe_stroke_team_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discharge disability outcome multiclass model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data for features for the outcome model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outcome = data[selected_features_mrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_ohe = list(data_outcome)\n",
    "feature_names_ohe.remove(\"discharge_disability\")\n",
    "n_features_ohe = len(feature_names_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit data\n",
    "### Divide into X (features) and y (labels)\n",
    "We will separate out our features (the data we use to make a prediction) from our label (what we are trying to predict).\n",
    "By convention our features are called `X` (usually upper case to denote multiple features), and the label (disability discharge) `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outcome = data_outcome.drop('discharge_disability', axis=1)\n",
    "y_outcome = data_outcome['discharge_disability']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit XGBoost model multiclass classification model for discharge disability\n",
    "\n",
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model filename\n",
    "filename = os.path.join(paths.model_save_path, \n",
    "                (paths.notebook + paths.model_text + '.p'))\n",
    "\n",
    "# Check if exists\n",
    "file_exists = exists(filename)\n",
    "\n",
    "if file_exists:\n",
    "# Load models\n",
    "    with open(filename, 'rb') as filehandler:\n",
    "        model_outcome = pickle.load(filehandler)\n",
    "else:\n",
    "    # Define and Fit model\n",
    "    model_outcome = XGBClassifier(verbosity=0, seed=42, learning_rate=0.5,\n",
    "                            tree_method='gpu_hist')\n",
    "    model_outcome.fit(X_outcome, y_outcome)\n",
    "\n",
    "    # Save using pickle\n",
    "    with open(filename, 'wb') as filehandler:\n",
    "        pickle.dump(model_outcome, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to calculate the population outcome (from the individual patient mRS probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_population_outcome(y_probs, mrs_classes):\n",
    "    weighted_mrs = (y_probs * mrs_classes).sum(axis=1)\n",
    "    return(np.average(weighted_mrs),weighted_mrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the classes from the multiclass model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_classes = model_outcome.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scenario: All patients are treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X data for all treated\n",
    "X_all_treated = data_outcome.drop('discharge_disability', axis=1)\n",
    "X_all_treated[\"onset_to_thrombolysis_time\"] = (\n",
    "                                    onset_to_thrombolysis_time_all_treated)\n",
    "\n",
    "# Calculate and store predicted outcome probabilities\n",
    "y_outcome_probs_all_treated = model_outcome.predict_proba(X_all_treated)\n",
    "\n",
    "# Calculate weighted outcome per patient, and for population\n",
    "(ave_weighted_mrs_all_treated, weighted_mrs_all_treated) = (\n",
    "        calculate_population_outcome(y_outcome_probs_all_treated, mrs_classes))\n",
    "\n",
    "mask_all_treated = X_all_treated[\"onset_to_thrombolysis_time\"] > -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scenario: No patients are treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X data for none treated\n",
    "X_none_treated = data_outcome.drop('discharge_disability', axis=1)\n",
    "X_none_treated[\"onset_to_thrombolysis_time\"] = -100\n",
    "\n",
    "# Calculate and store predicted outcome probabilities\n",
    "y_outcome_probs_none_treated = model_outcome.predict_proba(X_none_treated)\n",
    "\n",
    "# Calculate weighted outcome per patient, and for population\n",
    "(ave_weighted_mrs_none_treated, weighted_mrs_none_treated) = (\n",
    "    calculate_population_outcome(y_outcome_probs_none_treated, mrs_classes))\n",
    "\n",
    "mask_none_treated = X_none_treated[\"onset_to_thrombolysis_time\"] > -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scenario: Actual treatment decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and store predicted outcome probabilities\n",
    "y_outcome_probs = model_outcome.predict_proba(X_outcome)\n",
    "\n",
    "# Calculate weighted outcome per patient, and for population\n",
    "(ave_weighted_mrs_actual_treatment, weighted_mrs_actual_treatment) = (\n",
    "                    calculate_population_outcome(y_outcome_probs, mrs_classes))\n",
    "\n",
    "mask_actual_treatment = X_outcome[\"onset_to_thrombolysis_time\"] > -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scenario: Benchmark treatment decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the 25 benchmark hospitals (identified in notebook 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(paths.data_save_path, \n",
    "    ('200_xgb_10_features_all_data_thrombolysis_decision_highest_25_benchmark_'\n",
    "     'hospitals_median_shap.csv'))\n",
    "\n",
    "benchmark_hospitals = pd.read_csv(filename)\n",
    "benchmark_hospitals = list(benchmark_hospitals['hospital'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open model to get thrombolysis decision based on benchmark hospitals\n",
    "\n",
    "# Model filename\n",
    "filename_treatment_model = os.path.join(paths.model_save_path, \n",
    "                '200_xgb_10_features_all_data_thrombolysis_decision.p')\n",
    "\n",
    "# Check if exists\n",
    "file_exists = exists(filename_treatment_model)\n",
    "\n",
    "if file_exists:\n",
    "# Load models\n",
    "    with open(filename_treatment_model, 'rb') as filehandler:\n",
    "        model_treatment_decision = pickle.load(filehandler)\n",
    "else:\n",
    "    # give warning message\n",
    "    print(\"Run notebook 200 to fit the treatment decision model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset for the treatment decision model\n",
    "data_treatment_decision = data[selected_features_treatment]\n",
    "X_treatment_decision = data_treatment_decision.drop('S2Thrombolysis', axis=1)\n",
    "\n",
    "# Initialise dataframe to store benchmark hospital retults\n",
    "df_benchmark_decisions = pd.DataFrame()\n",
    "\n",
    "# For each benchmark hosptial, send all patients there, get treatment decision\n",
    "for h in benchmark_hospitals:\n",
    "    X_treatment_decision[ohe_stroke_team_features] = 0\n",
    "    X_treatment_decision[f\"team_{h}\"] = 1\n",
    "    df_benchmark_decisions[f\"{h}\"] = (\n",
    "                    model_treatment_decision.predict(X_treatment_decision))\n",
    "\n",
    "# Calculate the majority vote from the 25 benchmark hosptials\n",
    "benchmark_decision = df_benchmark_decisions.sum(axis=1) > (25/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the benchmark decision whether to treat each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outcome_benchmark_decision = X_outcome.copy(deep=True)\n",
    "\n",
    "# Set all patients as having thrombolysis, then set those that benchmark not \n",
    "# give as -100\n",
    "X_outcome_benchmark_decision[\"onset_to_thrombolysis_time\"] = (\n",
    "                                    onset_to_thrombolysis_time_all_treated)\n",
    "mask_benchmark = benchmark_decision == 0\n",
    "X_outcome_benchmark_decision[\"onset_to_thrombolysis_time\"][mask_benchmark] = -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the population outcome for the scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and store predicted outcome probabilities\n",
    "y_outcome_probs_benchmark = model_outcome.predict_proba(\n",
    "                                                X_outcome_benchmark_decision)\n",
    "\n",
    "# Calculate weighted outcome per patient, and for population\n",
    "(ave_weighted_mrs_benchmark, weighted_mrs_benchmark) = (\n",
    "        calculate_population_outcome(y_outcome_probs_benchmark, mrs_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scenario: Best outcome decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_mrs_best_outcome = np.minimum(weighted_mrs_all_treated, \n",
    "                                   weighted_mrs_none_treated)\n",
    "mask_best_outcome = weighted_mrs_all_treated < weighted_mrs_none_treated\n",
    "ave_weighted_mrs_best_outcome = np.average(weighted_mrs_best_outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Scenario: Worst outcome decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_mrs_worst_outcome = np.maximum(weighted_mrs_all_treated, \n",
    "                                    weighted_mrs_none_treated)\n",
    "mask_worst_outcome = weighted_mrs_all_treated > weighted_mrs_none_treated\n",
    "ave_weighted_mrs_worst_outcome = np.average(weighted_mrs_worst_outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store number of patients with indifferent outcome (in terms of weighted mRS) based on treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_weighted_mrs_indifferent_outcome = (\n",
    "                    weighted_mrs_all_treated == weighted_mrs_none_treated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Scenario: Best likelihood of being mRS 0-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_mrs0_to_4_all_treated = y_outcome_probs_all_treated[:,0:5].sum(axis=1)\n",
    "proportion_mrs0_to_4_not_treated = y_outcome_probs_none_treated[:,0:5].sum(axis=1)\n",
    "mask_best_proportion = (\n",
    "            proportion_mrs0_to_4_all_treated > proportion_mrs0_to_4_not_treated)\n",
    "\n",
    "weighted_mrs_best_proportion = copy.deepcopy(weighted_mrs_none_treated)\n",
    "weighted_mrs_best_proportion[mask_best_proportion] = (\n",
    "                            weighted_mrs_all_treated[mask_best_proportion])\n",
    "\n",
    "ave_weighted_mrs_best_proportion = np.average(weighted_mrs_best_proportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Scenario: Worst likelihood of being mRS 0-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_worst_proportion = (\n",
    "            proportion_mrs0_to_4_all_treated < proportion_mrs0_to_4_not_treated)\n",
    "\n",
    "weighted_mrs_worst_proportion = copy.deepcopy(weighted_mrs_none_treated)\n",
    "weighted_mrs_worst_proportion[mask_worst_proportion] = (\n",
    "                            weighted_mrs_all_treated[mask_worst_proportion])\n",
    "ave_weighted_mrs_worst_proportion = np.average(weighted_mrs_worst_proportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store patients with indifferent outcome (in terms of likelihood of being mRS 0 - 4) based on treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_weighted_mrs_indifferent_proportion = (\n",
    "    proportion_mrs0_to_4_all_treated == proportion_mrs0_to_4_not_treated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise dataframe to store which patients got treatment in each scenario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treatment_decision_per_scenario = pd.DataFrame()\n",
    "\n",
    "df_treatment_decision_per_scenario[\"All_treated\"] = weighted_mrs_all_treated\n",
    "df_treatment_decision_per_scenario[\"None_treated\"] = weighted_mrs_none_treated\n",
    "df_treatment_decision_per_scenario[\"Actual_treatment_decision\"] = weighted_mrs_actual_treatment\n",
    "df_treatment_decision_per_scenario[\"Benchmark_treatment_decision\"] = weighted_mrs_benchmark\n",
    "df_treatment_decision_per_scenario[\"Best_weighted_outcome\"] = weighted_mrs_best_outcome\n",
    "df_treatment_decision_per_scenario[\"Worst_weighted_outcome\"] = weighted_mrs_worst_outcome\n",
    "df_treatment_decision_per_scenario[\"Best_proportion_outcome\"] = weighted_mrs_best_proportion\n",
    "df_treatment_decision_per_scenario[\"Worst_proportion_outcome\"] = weighted_mrs_worst_proportion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All_treated</th>\n",
       "      <th>None_treated</th>\n",
       "      <th>Actual_treatment_decision</th>\n",
       "      <th>Benchmark_treatment_decision</th>\n",
       "      <th>Best_weighted_outcome</th>\n",
       "      <th>Worst_weighted_outcome</th>\n",
       "      <th>Best_proportion_outcome</th>\n",
       "      <th>Worst_proportion_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>168347.000000</td>\n",
       "      <td>168347.000000</td>\n",
       "      <td>168347.000000</td>\n",
       "      <td>168347.000000</td>\n",
       "      <td>168347.000000</td>\n",
       "      <td>168347.000000</td>\n",
       "      <td>168347.000000</td>\n",
       "      <td>168347.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.610979</td>\n",
       "      <td>2.703880</td>\n",
       "      <td>2.623641</td>\n",
       "      <td>2.589765</td>\n",
       "      <td>2.501352</td>\n",
       "      <td>2.813508</td>\n",
       "      <td>2.541487</td>\n",
       "      <td>2.773374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.284881</td>\n",
       "      <td>1.368008</td>\n",
       "      <td>1.353737</td>\n",
       "      <td>1.343546</td>\n",
       "      <td>1.298883</td>\n",
       "      <td>1.338232</td>\n",
       "      <td>1.286688</td>\n",
       "      <td>1.358024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.164073</td>\n",
       "      <td>0.200679</td>\n",
       "      <td>0.172511</td>\n",
       "      <td>0.172135</td>\n",
       "      <td>0.164073</td>\n",
       "      <td>0.223307</td>\n",
       "      <td>0.164073</td>\n",
       "      <td>0.172511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.577787</td>\n",
       "      <td>1.582016</td>\n",
       "      <td>1.522846</td>\n",
       "      <td>1.499427</td>\n",
       "      <td>1.448674</td>\n",
       "      <td>1.731251</td>\n",
       "      <td>1.492857</td>\n",
       "      <td>1.673468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.320550</td>\n",
       "      <td>2.368757</td>\n",
       "      <td>2.278913</td>\n",
       "      <td>2.243767</td>\n",
       "      <td>2.172313</td>\n",
       "      <td>2.502002</td>\n",
       "      <td>2.253733</td>\n",
       "      <td>2.434643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.515585</td>\n",
       "      <td>3.739424</td>\n",
       "      <td>3.605040</td>\n",
       "      <td>3.550561</td>\n",
       "      <td>3.427972</td>\n",
       "      <td>3.832023</td>\n",
       "      <td>3.443732</td>\n",
       "      <td>3.819390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.947370</td>\n",
       "      <td>5.938540</td>\n",
       "      <td>5.938540</td>\n",
       "      <td>5.938540</td>\n",
       "      <td>5.938540</td>\n",
       "      <td>5.947370</td>\n",
       "      <td>5.939654</td>\n",
       "      <td>5.947370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         All_treated   None_treated  Actual_treatment_decision  \\\n",
       "count  168347.000000  168347.000000              168347.000000   \n",
       "mean        2.610979       2.703880                   2.623641   \n",
       "std         1.284881       1.368008                   1.353737   \n",
       "min         0.164073       0.200679                   0.172511   \n",
       "25%         1.577787       1.582016                   1.522846   \n",
       "50%         2.320550       2.368757                   2.278913   \n",
       "75%         3.515585       3.739424                   3.605040   \n",
       "max         5.947370       5.938540                   5.938540   \n",
       "\n",
       "       Benchmark_treatment_decision  Best_weighted_outcome  \\\n",
       "count                 168347.000000          168347.000000   \n",
       "mean                       2.589765               2.501352   \n",
       "std                        1.343546               1.298883   \n",
       "min                        0.172135               0.164073   \n",
       "25%                        1.499427               1.448674   \n",
       "50%                        2.243767               2.172313   \n",
       "75%                        3.550561               3.427972   \n",
       "max                        5.938540               5.938540   \n",
       "\n",
       "       Worst_weighted_outcome  Best_proportion_outcome  \\\n",
       "count           168347.000000            168347.000000   \n",
       "mean                 2.813508                 2.541487   \n",
       "std                  1.338232                 1.286688   \n",
       "min                  0.223307                 0.164073   \n",
       "25%                  1.731251                 1.492857   \n",
       "50%                  2.502002                 2.253733   \n",
       "75%                  3.832023                 3.443732   \n",
       "max                  5.947370                 5.939654   \n",
       "\n",
       "       Worst_proportion_outcome  \n",
       "count             168347.000000  \n",
       "mean                   2.773374  \n",
       "std                    1.358024  \n",
       "min                    0.172511  \n",
       "25%                    1.673468  \n",
       "50%                    2.434643  \n",
       "75%                    3.819390  \n",
       "max                    5.947370  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treatment_decision_per_scenario.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model filename\n",
    "filename = os.path.join(paths.data_save_path, \n",
    "                (paths.notebook + paths.model_text + '_scenario_treatment_decision_results.csv'))\n",
    "\n",
    "df_treatment_decision_per_scenario.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise dataframe to store patients mrs probabilites in each scenario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weighted_mrs_per_scenario = pd.DataFrame()\n",
    "\n",
    "df_weighted_mrs_per_scenario[\"All_treated\"] = weighted_mrs_all_treated \n",
    "df_weighted_mrs_per_scenario[\"None_treated\"] = weighted_mrs_none_treated\n",
    "df_weighted_mrs_per_scenario[\"Actual_treatment_decision\"] = weighted_mrs_actual_treatment\n",
    "df_weighted_mrs_per_scenario[\"Benchmark_treatment_decision\"] = weighted_mrs_benchmark\n",
    "df_weighted_mrs_per_scenario[\"Best_weighted_outcome\"] = weighted_mrs_best_outcome\n",
    "df_weighted_mrs_per_scenario[\"Worst_weighted_outcome\"] = weighted_mrs_worst_outcome\n",
    "df_weighted_mrs_per_scenario[\"Best_proportion_outcome\"] = weighted_mrs_best_proportion\n",
    "df_weighted_mrs_per_scenario[\"Worst_proportion_outcome\"] = weighted_mrs_worst_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All_treated</th>\n",
       "      <th>None_treated</th>\n",
       "      <th>Actual_treatment_decision</th>\n",
       "      <th>Benchmark_treatment_decision</th>\n",
       "      <th>Best_weighted_outcome</th>\n",
       "      <th>Worst_weighted_outcome</th>\n",
       "      <th>Best_proportion_outcome</th>\n",
       "      <th>Worst_proportion_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>168347.000000</td>\n",
       "      <td>168347.000000</td>\n",
       "      <td>168347.000000</td>\n",
       "      <td>168347.000000</td>\n",
       "      <td>168347.000000</td>\n",
       "      <td>168347.000000</td>\n",
       "      <td>168347.000000</td>\n",
       "      <td>168347.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.610979</td>\n",
       "      <td>2.703880</td>\n",
       "      <td>2.623641</td>\n",
       "      <td>2.589765</td>\n",
       "      <td>2.501352</td>\n",
       "      <td>2.813508</td>\n",
       "      <td>2.541487</td>\n",
       "      <td>2.773374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.284881</td>\n",
       "      <td>1.368008</td>\n",
       "      <td>1.353737</td>\n",
       "      <td>1.343546</td>\n",
       "      <td>1.298883</td>\n",
       "      <td>1.338232</td>\n",
       "      <td>1.286688</td>\n",
       "      <td>1.358024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.164073</td>\n",
       "      <td>0.200679</td>\n",
       "      <td>0.172511</td>\n",
       "      <td>0.172135</td>\n",
       "      <td>0.164073</td>\n",
       "      <td>0.223307</td>\n",
       "      <td>0.164073</td>\n",
       "      <td>0.172511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.577787</td>\n",
       "      <td>1.582016</td>\n",
       "      <td>1.522846</td>\n",
       "      <td>1.499427</td>\n",
       "      <td>1.448674</td>\n",
       "      <td>1.731251</td>\n",
       "      <td>1.492857</td>\n",
       "      <td>1.673468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.320550</td>\n",
       "      <td>2.368757</td>\n",
       "      <td>2.278913</td>\n",
       "      <td>2.243767</td>\n",
       "      <td>2.172313</td>\n",
       "      <td>2.502002</td>\n",
       "      <td>2.253733</td>\n",
       "      <td>2.434643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.515585</td>\n",
       "      <td>3.739424</td>\n",
       "      <td>3.605040</td>\n",
       "      <td>3.550561</td>\n",
       "      <td>3.427972</td>\n",
       "      <td>3.832023</td>\n",
       "      <td>3.443732</td>\n",
       "      <td>3.819390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.947370</td>\n",
       "      <td>5.938540</td>\n",
       "      <td>5.938540</td>\n",
       "      <td>5.938540</td>\n",
       "      <td>5.938540</td>\n",
       "      <td>5.947370</td>\n",
       "      <td>5.939654</td>\n",
       "      <td>5.947370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         All_treated   None_treated  Actual_treatment_decision  \\\n",
       "count  168347.000000  168347.000000              168347.000000   \n",
       "mean        2.610979       2.703880                   2.623641   \n",
       "std         1.284881       1.368008                   1.353737   \n",
       "min         0.164073       0.200679                   0.172511   \n",
       "25%         1.577787       1.582016                   1.522846   \n",
       "50%         2.320550       2.368757                   2.278913   \n",
       "75%         3.515585       3.739424                   3.605040   \n",
       "max         5.947370       5.938540                   5.938540   \n",
       "\n",
       "       Benchmark_treatment_decision  Best_weighted_outcome  \\\n",
       "count                 168347.000000          168347.000000   \n",
       "mean                       2.589765               2.501352   \n",
       "std                        1.343546               1.298883   \n",
       "min                        0.172135               0.164073   \n",
       "25%                        1.499427               1.448674   \n",
       "50%                        2.243767               2.172313   \n",
       "75%                        3.550561               3.427972   \n",
       "max                        5.938540               5.938540   \n",
       "\n",
       "       Worst_weighted_outcome  Best_proportion_outcome  \\\n",
       "count           168347.000000            168347.000000   \n",
       "mean                 2.813508                 2.541487   \n",
       "std                  1.338232                 1.286688   \n",
       "min                  0.223307                 0.164073   \n",
       "25%                  1.731251                 1.492857   \n",
       "50%                  2.502002                 2.253733   \n",
       "75%                  3.832023                 3.443732   \n",
       "max                  5.947370                 5.939654   \n",
       "\n",
       "       Worst_proportion_outcome  \n",
       "count             168347.000000  \n",
       "mean                   2.773374  \n",
       "std                    1.358024  \n",
       "min                    0.172511  \n",
       "25%                    1.673468  \n",
       "50%                    2.434643  \n",
       "75%                    3.819390  \n",
       "max                    5.947370  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weighted_mrs_per_scenario.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model filename\n",
    "filename = os.path.join(paths.data_save_path, \n",
    "    (paths.notebook + paths.model_text + '_scenario_weighted_mrs_results.csv'))\n",
    "\n",
    "df_weighted_mrs_per_scenario.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KP YOU ARE HERE\n",
    "\n",
    "Most strokes are mild, they are getting the least effect from IVT. So this weights the outcome to be a smaller effect.\n",
    "\n",
    "If look just at moderate strokes, or severe stroke, with no prior disability, this may have a bigger effect.\n",
    "\n",
    "What is your average predicted disability w/o thrombolysis. Expect ot see a bigger effect of IVT. The worse our predicted outcome, on ave the better the effect of IVT. Largely an effect of stroke severity (0-4, 5-10, 11-15, etc... expect to see a bigger shift).\n",
    "\n",
    "Which patients are the 126 patients with indifferent outcomes for treatment. Where's the break even point.\n",
    "\n",
    "Interesting to look at, use a differnt decision for whether to treat. Rather than the average mRS distribution, use what if made decision based on do you improve the proportion that are less than mRS5 (0-4, vs 5-6). Do I improve the chance of not having a . Which are both improved shift, and improved reduction in being mRS5&6.\n",
    "\n",
    "Shift most of the bulk to the left, but see an increase in mRS5&6.\n",
    "\n",
    "Two different models, (5 and 6). Improved disability, and avoid a bad outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6088/952832258.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stroke_severity\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_treatment_per_scenario_nihss_0_to_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_treatment_decision_per_scenario\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stroke_severity\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stroke_severity\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_treatment_per_scenario_nihss_5_to_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_treatment_decision_per_scenario\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stroke_severity\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stroke_severity\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sam10/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1527\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1528\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "mask = data[\"stroke_severity\"] < 5\n",
    "df_treatment_per_scenario_nihss_0_to_4 = df_treatment_decision_per_scenario[mask]\n",
    "\n",
    "mask = (data[\"stroke_severity\"] > 4 and data[\"stroke_severity\"] < 11)\n",
    "df_treatment_per_scenario_nihss_5_to_10 = df_treatment_decision_per_scenario[mask]\n",
    "\n",
    "mask = (data[\"stroke_severity\"] > 10 and data[\"stroke_severity\"] < 16)\n",
    "df_treatment_per_scenario_nihss_11_to_15 = df_treatment_decision_per_scenario[mask]\n",
    "\n",
    "mask = data[\"stroke_severity\"] > 30\n",
    "df_treatment_per_scenario_nihss_30_plus = df_treatment_decision_per_scenario[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot (want to create a subplot per patient, with the two mRS probability distributions on the same plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_for_bar_plot(df):\n",
    "    df_bar  = pd.DataFrame()\n",
    "    df_bar[\"Treatment\"] = ([\"Treatment\"] * 7) + ([\"No treatment\"] * 7)\n",
    "    df_bar[\"Discharge disability\"] = np.append(df.index.values, df.index.values)\n",
    "    df_bar[\"Probability\"] = np.append(df[\"with\"], df[\"without\"])\n",
    "    return(df_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for these patients, and store (\\ dataframe for getting IVT, and a dataframe for not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_patients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kerry/Documents/GitHub/stroke_outcome_ml/xgb_7_features/210_xgb_all_data_7_features_multiclass_outcome.ipynb Cell 90\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kerry/Documents/GitHub/stroke_outcome_ml/xgb_7_features/210_xgb_all_data_7_features_multiclass_outcome.ipynb#Y136sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m list_onset_to_thrombolysis_time \u001b[39m=\u001b[39m [ott_default, \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kerry/Documents/GitHub/stroke_outcome_ml/xgb_7_features/210_xgb_all_data_7_features_multiclass_outcome.ipynb#Y136sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m list_figures \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kerry/Documents/GitHub/stroke_outcome_ml/xgb_7_features/210_xgb_all_data_7_features_multiclass_outcome.ipynb#Y136sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m patient_loc \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_patients):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kerry/Documents/GitHub/stroke_outcome_ml/xgb_7_features/210_xgb_all_data_7_features_multiclass_outcome.ipynb#Y136sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kerry/Documents/GitHub/stroke_outcome_ml/xgb_7_features/210_xgb_all_data_7_features_multiclass_outcome.ipynb#Y136sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# take details of this patient\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kerry/Documents/GitHub/stroke_outcome_ml/xgb_7_features/210_xgb_all_data_7_features_multiclass_outcome.ipynb#Y136sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     df_patient_details \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(df_patient_prototypes), index\u001b[39m=\u001b[39m\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(list_get_treatment)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kerry/Documents/GitHub/stroke_outcome_ml/xgb_7_features/210_xgb_all_data_7_features_multiclass_outcome.ipynb#Y136sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# take exact copy of row\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_patients' is not defined"
     ]
    }
   ],
   "source": [
    "list_get_treatment = [\"Treatment\",\"No treatment\"]\n",
    "list_onset_to_thrombolysis_time = [ott_default, -100]\n",
    "\n",
    "list_figures = []\n",
    "\n",
    "for patient_loc in range(n_patients):\n",
    "\n",
    "    # take details of this patient\n",
    "    df_patient_details = pd.DataFrame(columns=list(df_patient_prototypes), index=range(len(list_get_treatment)))\n",
    "\n",
    "    # take exact copy of row\n",
    "    df_patient_details.iloc[0] = df_patient_prototypes.iloc[0,:]\n",
    "    df_patient_details.iloc[1] = df_patient_prototypes.iloc[0,:]\n",
    "\n",
    "    # make first copy have, and the second copy not have thrombolysis treatment (either not get, or get at 2 hours)\n",
    "    df_patient_details[\"onset_to_thrombolysis_time\"] = list_onset_to_thrombolysis_time\n",
    "\n",
    "    df_patient_details = df_patient_details.astype('float')\n",
    "\n",
    "    y_probs = model.predict_proba(df_patient_details)\n",
    "    y_pred = model.predict(df_patient_details)\n",
    "\n",
    "    df_patient_mrs_results = pd.DataFrame(\n",
    "            data=y_probs, \n",
    "            columns=[\"mRS0\",\"mRS1\",\"mRS2\",\"mRS3\",\"mRS4\",\"mRS5\",\"mRS6\"], \n",
    "            index=[\"with\",\"without\"])\n",
    "\n",
    "    df_patient_mrs_results = df_patient_mrs_results.T\n",
    "\n",
    "    df_bar = create_df_for_bar_plot(df_patient_mrs_results)\n",
    "\n",
    "#    ax = fig.add_subplot(n_patients, 1, patient_loc + 1)\n",
    "    plotly_express_figure = px.bar(df_bar, x=\"Discharge disability\", y=\"Probability\", \n",
    "                color=\"Treatment\", barmode=\"group\")\n",
    "    \n",
    "    list_figures.append(plotly_express_figure)\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=len(list_figures), cols=1) \n",
    "\n",
    "for i, figure in enumerate(list_figures):\n",
    "    for trace in range(len(figure[\"data\"])):\n",
    "        \n",
    "        fig.append_trace(figure[\"data\"][trace], row=i+1, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=1600#,\n",
    "#            title=f\"{df_patient_prototypes.index.values[patient_loc]}\",\n",
    "#            xaxis_title=\"Discharge disability\",\n",
    "#            yaxis_title=\"Probability\",\n",
    "#            legend_title=\"Legend Title\",\n",
    "#            font=dict(\n",
    "#                family=\"Courier New, monospace\",\n",
    "#                size=18,\n",
    "#                color=\"RebeccaPurple\"\n",
    "#            )\n",
    ")\n",
    "#names = {'Plot 1':'2016', 'Plot 2':'2017', 'Plot 3':'2018', 'Plot 4':'2019'}\n",
    "\n",
    "#fig.for_each_annotation(lambda a: a.update(text = df_patient_prototypes.index.values[patient_loc]))\n",
    "         \n",
    "fig.show()\n",
    "\n",
    "#plot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CELLS BELOW ARE CREATING A SINGLE FIGURE TO EXPERIMENT WITH THE PARAMETERS TO MAKE THE ABOVE SUBPLOT VERSION LOOK HOW WE WANT.\n",
    "\n",
    "TO DO: \n",
    "1. Legend only have 1 entry per colour\n",
    "1. Titles of the patient type for each subplot\n",
    "1. X and Y axis labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_get_treatment = [\"Treatment\",\"No treatment\"]\n",
    "list_onset_to_thrombolysis_time = [ott_default, -100]\n",
    "\n",
    "# take details of this patient\n",
    "df_patient_details = pd.DataFrame(columns=list(df_patient_prototypes), index=range(len(list_get_treatment)))\n",
    "\n",
    "# take exact copy of row\n",
    "df_patient_details.iloc[0] = df_patient_prototypes.iloc[0,:]\n",
    "df_patient_details.iloc[1] = df_patient_prototypes.iloc[0,:]\n",
    "\n",
    "# make first copy have, and the second copy not have thrombolysis treatment (either not get, or get at 2 hours)\n",
    "df_patient_details[\"onset_to_thrombolysis_time\"] = list_onset_to_thrombolysis_time\n",
    "\n",
    "df_patient_details = df_patient_details.astype('float')\n",
    "\n",
    "df_patient_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = model.predict_proba(df_patient_details)\n",
    "y_pred = model.predict(df_patient_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient_mrs_results = pd.DataFrame(\n",
    "            data=y_probs, \n",
    "            columns=[\"mRS0\",\"mRS1\",\"mRS2\",\"mRS3\",\"mRS4\",\"mRS5\",\"mRS6\"], \n",
    "            index=[\"with\",\"without\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient_mrs_results = df_patient_mrs_results.T\n",
    "df_patient_mrs_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bar = create_df_for_bar_plot(df_patient_mrs_results)\n",
    "df_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(df_bar, x=\"Discharge disability\", y=\"Probability\", \n",
    "                color=\"Treatment\", barmode=\"group\")# title=f\"{df_patient_details.index.value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('sam10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f85b883bff9a8a9f39576b94acbdf6672b3dc17c35647e7395f81e785740a4b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
