{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which patients would get treatment based on different ways to make the decision to give treatment (notebook 2 from set of n)\n",
    "Answering a question raised from the results from notebook 210: Which type of patients have indifferent outcomes with treatment?\\\n",
    "(see notebooks 211, 212, 214 for other questions)\n",
    "\n",
    "### Plain English summary\n",
    "\n",
    "Analyse the impact of 14 scenarios for deciding who gets treatment. How does this difference in decision making affect patient outcomes? Here we also explore different ways of defining the 'best outcome'.\n",
    "\n",
    "The 14 scenarios (different ways of selecting which patient to give treatment to):\n",
    "1. All patients are treated\n",
    "1. No patients are treated\n",
    "1. Actual treatment decision\n",
    "1. High-benchmark treatment decision (25 hospitals with highest SHAP hospital value)\n",
    "1. Low-benchmark treatment decision (25 hospitals with lowest SHAP hospital value)\n",
    "1. Best weighted mRS outcome decision\n",
    "1. Worst weighted mRS outcome decision\n",
    "1. Best likelihood of being mRS 0-4\n",
    "1. Worst likelihood of being mRS 0-4\n",
    "1. Best weighted mRS and best likelihood of being mRS 0-4\n",
    "1. Worse weighted mRS and worse likelihood of being mRS 0-4\n",
    "1. Best weighted mRS outcome decision where everyone has door to needle of 30 mins if they are treated \n",
    "1. Only choose treatment if it improves the mRS by +0.2\n",
    "1. Only choose treatment if it improves the mRS by +0.2 and not increase the likelihood of a bad outcome (>= mRS 5) [a given benefit without risk of increased risk of bad outcome]\n",
    "\n",
    "For each scenario we set up the feature \"onset-to-thrombolysis-time\" depending on whether the patient gets treatment in the scenario (we make use of the decision to treat model to obtain the bechmark decision to treat). We then pass this edited X_data to the outcome model to predict the mRS distribution for each patient (given them having treatment, or not), and report the population outcome for this decision to treat scenario.\n",
    "\n",
    "### Model and data\n",
    "\n",
    "#### Models\n",
    "This notebook uses two XGBoost models.\n",
    "\n",
    "1) Model to predict whether get treatment \n",
    "\n",
    "Model: XGBoost classifier [from notebook 200]\\\n",
    "Target feature: Give thrombolysis\\\n",
    "Input features: 9 features (prior_disability, stroke_severity, stroke_team, age, onset_to_arrival_time, arrival_to_scan_time, precise_onset_known, onset_during_sleep, afib_anticoagulant)\\\n",
    "Kfold split: First kfold split\n",
    "\n",
    "\n",
    "Note: The original thrombolysis choice model had 10 features. For this analysis, we only have ischaemic patients, and don't include anyone taking AF anticoagulants, so no need for those two related features\n",
    "\n",
    "2) Model to predict the disability at discharge\n",
    "\n",
    "Model: XGBoost classifier (multiclass classification) [from notebook 040]\\\n",
    "Target feature: Discharge disability\\\n",
    "Input features: 7 features (prior_disability, stroke_severity, stroke_team, age, onset_to_thrombolysis_time, any_afib_diagnosis, precise_onset_known)\\\n",
    "Kfold split: First kfold split\n",
    "\n",
    "Use the model to predict each patients mRS probability distributions with/without thrombolysis (individual mRS probability, cumulative probability distributions, and weighted mRS). The scenario will determine whether the patient gets treatment. For those patients that did not get thrombolysis in the observed dataset, assume their scan-to-treatment is the median of the hospital attended.\n",
    "\n",
    "#### Data.\n",
    "\n",
    "Use dataset '02_reformatted_data_ml_include_mt.csv'\n",
    "\n",
    "This analysis includes patients that are:\n",
    "* Scanned within 4 hrs 15 mins of onset\n",
    "* Ischaemic strokes (filter included in input dataset '02_reformatted_data_ml_include_mt.csv')\n",
    "* Can have had thrombectomy (included in input dataset '02_reformatted_data_ml_include_mt.csv')\n",
    "\n",
    "### Aims\n",
    "\n",
    "### Observations\n",
    "\n",
    "\n",
    "#### Further work\n",
    "Is benchmark just really defined by people giving thtrombolysis to the large group of people with mild strokes.\n",
    "\n",
    "Opposing approaches for giving IVT:\n",
    "Not too worreid how much benefit give, just so long as not doing harm.\n",
    "Or the other way is only giving it when I see there's a clear reason to.\n",
    "\n",
    "#### Resources\n",
    "pip install plotly\n",
    "pip install dash\n",
    "\n",
    "https://github.com/timyerg/venny4py?tab=readme-ov-file\n",
    "https://github.com/tctianchi/pyvenn\n",
    "https://pypi.org/project/venn/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn warnings off to keep notebook tidy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from os.path import exists\n",
    "\n",
    "import math\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator #force all mrs categories to be shown on the x axis\n",
    "\n",
    "import time\n",
    "\n",
    "# for venn diagram (pip install matplotlib_venn)\n",
    "# https://pypi.org/project/matplotlib-venn/\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "from matplotlib_venn import venn3, venn3_circles\n",
    "\n",
    "# for venn diagram with 3+ sets (pip install venny4py)\n",
    "from venny4py.venny4py import *\n",
    "\n",
    "# For the 3+ sets venn diagram\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "# for radar plot\n",
    "from matplotlib.patches import Circle, RegularPolygon\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.projections import register_projection\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from matplotlib.spines import Spine\n",
    "from matplotlib.transforms import Affine2D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the time duration to run notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set to use only the first kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the features for the model to predict disability discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_mrs = [\"prior_disability\", \"stroke_severity\", \"stroke_team\", \n",
    "                         \"age\", \"onset_to_thrombolysis_time\", \"any_afib_diagnosis\", \n",
    "                         \"precise_onset_known\", \"discharge_disability\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the features for the model to predict decision to give thrombolysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_treatment = [\"prior_disability\", \"stroke_severity\", \n",
    "                     \"age\", \"arrival_to_scan_time\", \"precise_onset_known\", \n",
    "                     \"onset_to_arrival_time\",\"onset_during_sleep\", \n",
    "                     \"afib_anticoagulant\", \"stroke_team\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get union of both sets of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_set = list(set.union(set(selected_features_mrs), \n",
    "                                       set(selected_features_treatment)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up paths and filenames\n",
    "\n",
    "For consistency, the folders end with \"/\" and the text for filenames include no trailing \"_\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Paths:\n",
    "    '''Singleton object for storing paths to data and database.'''\n",
    "    image_save_path: str = './saved_images'\n",
    "    model_save_path: str = './saved_models'\n",
    "    data_save_path: str = './saved_data'\n",
    "    data_read_path: str = '../data_processing/output'\n",
    "    model_text: str = 'xgb_all_data_multiclass_outcome'\n",
    "    notebook: str = '213_'\n",
    "\n",
    "paths = Paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create output folders if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = paths.image_save_path\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "        \n",
    "path = paths.model_save_path\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "path = paths.data_save_path\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "Read in the full dataset (not kfold splits). Include patients that may have had thrombectomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in training set, restrict to chosen features & store\n",
    "filename = os.path.join(paths.data_read_path, \n",
    "                        '02_reformatted_data_ml_include_mt.csv')\n",
    "data_all_features = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter patients\n",
    "Keep only patients with onset to scan time of 4hours 15mins (so 15 mins to treat). This is 255 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (data_all_features[\"onset_to_arrival_time\"] + data_all_features[\"arrival_to_scan_time\"]) <= 255\n",
    "data_all_features = data_all_features[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store number fo patients in analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patients = data_all_features.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store data details prior to one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store stroke team attended (before one hot encode it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stroke_team = data_all_features[\"stroke_team\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create series \"onset_to_thrombolysis_time_all_treated\" for all patients.\n",
    "\n",
    "To be used for the scenarios when patients that are not treated in the dataset are treated in the scenario (they are without a scan to treatment time, use the average for the hospital they attended)\n",
    "\n",
    "First calculate the average scan_to_thrombolysis_time for those patients that got treated (per hospital) as then use this for those that do not get treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    118.000000\n",
       "mean      33.351695\n",
       "std        9.763071\n",
       "min       13.000000\n",
       "25%       27.000000\n",
       "50%       33.000000\n",
       "75%       40.000000\n",
       "max       75.000000\n",
       "Name: scan_to_thrombolysis_time, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median scan to treatment for the treated patients (per hosptial)\n",
    "mask_treatment = data_all_features[\"onset_to_thrombolysis_time\"] > -100\n",
    "median_scan_to_needle_time = (\n",
    "    data_all_features[mask_treatment].groupby([\"stroke_team\"])[\"scan_to_thrombolysis_time\"].median())\n",
    "\n",
    "median_scan_to_needle_time.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new series \"onset_to_thrombolysis_time_all_treated\" which takes the dataset value for those patients that are treated in the dataset. For those patients that are not treated in the dataset add the median hospital scan to treatment time to their individual onset to scan times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify patients not recieve treatment in the dataset\n",
    "mask_not_treated = data_all_features[\"scan_to_thrombolysis_time\"] == -100\n",
    "\n",
    "# Take a deep copy of the onset to thrombolysis time. This will remain unchanged \n",
    "# for those patients that recieve treatment in the dataset\n",
    "onset_to_thrombolysis_time_all_treated = data_all_features[\"onset_to_thrombolysis_time\"].copy(deep=True)\n",
    "\n",
    "# For those patients not recieve treatment in the dataset, use the median scan to treatment of their attended hosptial\n",
    "onset_to_scan_time = data_all_features[\"onset_to_arrival_time\"] + data_all_features[\"arrival_to_scan_time\"]\n",
    "onset_to_thrombolysis_time_all_treated[mask_not_treated] = (\n",
    "    onset_to_scan_time[mask_not_treated] + \n",
    "    median_scan_to_needle_time[data_all_features[\"stroke_team\"]].values[mask_not_treated])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create series \"onset_to_thrombolysis_time_all_treated_30mins_d2n\" for all patients.\n",
    "\n",
    "Repeat all of the 8 scenarios as if all hospitals are able to treat patients with a 30 minute door to needle time (use patients own onset to scan times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a deep copy of the onset to thrombolysis time. This will remain unchanged \n",
    "# for those patients that recieve treatment in the dataset\n",
    "onset_to_thrombolysis_time_all_treated_30mins_d2n = (\n",
    "    data_all_features[\"onset_to_arrival_time\"] + data_all_features[\"arrival_to_scan_time\"] + 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create series \"onset_to_thrombolysis_time_all_treated_within_30mins_d2n\" for all patients.\n",
    "\n",
    "Repeat all of the 8 scenarios as if all hospitals are able to treat patients within a 30 minute door to needle time (use patients own door to needle time if < 30 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_30mins_d2n = (\n",
    "    np.minimum(np.array([30]*n_patients), \n",
    "               data_all_features[\"scan_to_thrombolysis_time\"].replace(-100,9999)))\n",
    "\n",
    "onset_to_thrombolysis_time_all_treated_within_30mins_d2n = (\n",
    "                    data_all_features[\"onset_to_arrival_time\"] + \n",
    "                    data_all_features[\"arrival_to_scan_time\"] + \n",
    "                    within_30mins_d2n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select features to use in both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_all_features[selected_features_set].copy(deep=True)\n",
    "\n",
    "# Keep a copy of this dataset to use for the histograms (before the stroke team \n",
    "# is OHE)\n",
    "data_for_histogram = data.copy(deep=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot the categorical features\n",
    "\n",
    "Convert some categorical features to one hot encoded features.\n",
    "\n",
    "Define a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_feature_to_one_hot(df, feature_name, prefix):\n",
    "    \"\"\"\n",
    "    df [dataframe]: training or test dataset\n",
    "    feature_name [str]: feature to convert to ont hot encoding\n",
    "    prefix [str]: string to use on new feature\n",
    "    \"\"\"\n",
    "\n",
    "    # One hot encode a feature\n",
    "    df_feature = pd.get_dummies(\n",
    "        df[feature_name], prefix = prefix)\n",
    "    df = pd.concat([df, df_feature], axis=1)\n",
    "    df.drop(feature_name, axis=1, inplace=True)\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up two lists for the one hot encoding. \n",
    "\n",
    "A list of the feature names that are categorical and to be converted using one hot encoding.\n",
    "A list of the prefixes to use for these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_one_hot = [\"stroke_team\", \"weekday\"]\n",
    "list_prefix = [\"team\", \"weekday\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each feature in the list, for each train and test dataset, convert to one hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, prefix in zip(features_to_one_hot, list_prefix):\n",
    "    if feature in selected_features_set:\n",
    "        data = convert_feature_to_one_hot(data, feature, prefix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature names with one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_ohe = list(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the team names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_stroke_team_features = [col for col in feature_names_ohe if col.startswith('team')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the feature names to use in the model (remove \"stroke_team\" and add in all the one hot encoded feature names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the column name \"stroke_team\" with the ohe column names\n",
    "selected_features_mrs_ohe = selected_features_mrs\n",
    "selected_features_mrs_ohe.remove(\"stroke_team\")\n",
    "selected_features_mrs_ohe.extend(ohe_stroke_team_features)\n",
    "\n",
    "# replace the column name \"stroke_team\" with the ohe column names\n",
    "selected_features_treatment_ohe = selected_features_treatment\n",
    "selected_features_treatment_ohe.remove(\"stroke_team\")\n",
    "selected_features_treatment_ohe.extend(ohe_stroke_team_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get set of the features for both models (wtih ohe features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_set_ohe = list(set.union(set(selected_features_mrs_ohe), \n",
    "                                       set(selected_features_treatment_ohe)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discharge disability outcome multiclass model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data for features for the outcome model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outcome = data[selected_features_mrs_ohe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_ohe = list(data_outcome)\n",
    "feature_names_ohe.remove(\"discharge_disability\")\n",
    "n_features_ohe = len(feature_names_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit data\n",
    "### Divide into X (features) and y (labels)\n",
    "We will separate out our features (the data we use to make a prediction) from our label (what we are trying to predict).\n",
    "By convention our features are called `X` (usually upper case to denote multiple features), and the label (disability discharge) `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outcome = data_outcome.drop('discharge_disability', axis=1)\n",
    "y_outcome = data_outcome['discharge_disability']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load XGBoost model multiclass classification model for discharge disability\n",
    "From notebook 040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xgboost_model(filename):\n",
    "    \"\"\"\n",
    "    Given the filename, either load if the model exists (saved as a pickle), \n",
    "    else train a new model.\n",
    "\n",
    "    Args:\n",
    "        filename [string]: where xgboost model is saved\n",
    "        X_train [dataframe]: feature values\n",
    "        y_train [dataframe]: target feature\n",
    "        \n",
    "    Returns:\n",
    "        model [object]: xgboost classifier model\n",
    "\n",
    "    \"\"\"\n",
    "    # Check if exists\n",
    "    file_exists = exists(filename)\n",
    "\n",
    "    if file_exists:\n",
    "    # Load models\n",
    "        with open(filename, 'rb') as filehandler:\n",
    "            model = pickle.load(filehandler)\n",
    "    else:\n",
    "        # Print error\n",
    "        print(\"Run notebook 040 first to train the model\")\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model filename\n",
    "filename = os.path.join(paths.model_save_path, \n",
    "                ('040_xgb_7_features_5fold_0.p'))\n",
    "\n",
    "model_outcome = load_xgboost_model(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to calculate the population outcome (from the individual patient mRS probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_population_outcome(y_probs, mrs_classes):\n",
    "    weighted_mrs = (y_probs * mrs_classes).sum(axis=1)\n",
    "    return(np.average(weighted_mrs),weighted_mrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the classes from the multiclass model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_classes = model_outcome.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the results for the 14 scenarios for deciding which patients get treatment\n",
    "\n",
    "For this analysis, use this patient population:\n",
    "* Scanned within 4 hrs 15 mins of onset\n",
    "* Ischaemic stroke\n",
    "* Not taking anticolgalents\n",
    "* Not recieve thrombectomy\n",
    "\n",
    "The 14 scenarios (different ways of selecting which patient to give treatment to):\n",
    "1. All patients are treated\n",
    "1. No patients are treated\n",
    "1. Actual treatment decision\n",
    "1. High-benchmark treatment decision\n",
    "1. Low-benchmark treatment decision\n",
    "1. Best weighted mRS outcome decision\n",
    "1. Worst weighted mRS outcome decision\n",
    "1. Best likelihood of being mRS 0-4\n",
    "1. Worst likelihood of being mRS 0-4\n",
    "1. Best weighted mRS and best likelihood of being mRS 0-4\n",
    "1. Worse weighted mRS and worse likelihood of being mRS 0-4\n",
    "1. Best weighted mRS outcome decision where everyone has door to needle of 30 mins if they are treated \n",
    "1. Only choose treatment if it improves the mRS by +0.2\n",
    "1. Only choose treatment if it improves the mRS by +0.2 and not increase the likelihood of a bad outcome (>= mRS 5) [a given benefit without risk of increased risk of bad outcome]\n",
    "\n",
    "For each scenario we set up the feature \"onset-to-thrombolysis-time\" depending on whether the patient gets treatment in the scenario (we make use of the decision to treat model to obtain the bechmark decision to treat). We then pass this edited X_data to the outcome model to predict the mRS distribution for each patient (given them having treatment, or not), and report the population outcome for this decision to treat scenario.\n",
    "\n",
    "Read in data from first notebook in this set (from notebook 210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in as numpy array\n",
    "filename = os.path.join(paths.data_save_path, \n",
    "    ('210_' + paths.model_text + '_y_outcome_probs_all_treated.p'))\n",
    "\n",
    "with open(filename, 'rb') as filehandler:\n",
    "    y_outcome_probs_all_treated = pickle.load(filehandler)\n",
    "\n",
    "# Read in as numpy array\n",
    "filename = os.path.join(paths.data_save_path, \n",
    "    ('210_' + paths.model_text + '_y_outcome_probs_none_treated.p'))\n",
    "\n",
    "with open(filename, 'rb') as filehandler:\n",
    "    y_outcome_probs_none_treated = pickle.load(filehandler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(paths.data_save_path, \n",
    "                ('210_' + paths.model_text + '_dict_of_dataframes.p'))\n",
    "\n",
    "# Save using pickle\n",
    "with open(filename, 'rb') as filehandler:\n",
    "    dict_dataframes = pickle.load(filehandler)\n",
    "\n",
    "filename = os.path.join(paths.data_save_path, \n",
    "                ('210_' + paths.model_text + '_dict_of_scen_full_names.p'))\n",
    "\n",
    "# Save using pickle\n",
    "with open(filename, 'rb') as filehandler:\n",
    "    dict_scenario_information = pickle.load(filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treatment_decision_per_scenario = dict_dataframes[\"df_treated\"]\n",
    "df_weighted_mrs_per_scenario = dict_dataframes[\"df_weighted_mrs\"]\n",
    "df_mrs6_per_scenario = dict_dataframes[\"df_likelihood_mrs6\"]\n",
    "df_mrs5_6_per_scenario = dict_dataframes[\"df_likelihood_mrs5_6\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to create bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(xticks, bar_data, ax=None, title=\"\"):\n",
    "\n",
    "    ax = ax or plt.gca()\n",
    "\n",
    "    # Plot bars\n",
    "    pps = ax.bar(xticks, \n",
    "                bar_data)\n",
    "\n",
    "    ax.set_xticks(ax.get_xticks())\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', fontsize=8)\n",
    "\n",
    "    # Set axis labels\n",
    "    ax.set_xlabel(\"Treatment decision scenario\");\n",
    "    ax.set_ylabel(\"Percentage of patient population treated\");\n",
    "\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # annotate plot\n",
    "    for p in pps:\n",
    "        height = int(p.get_height())\n",
    "        ax.annotate('{}'.format(height),\n",
    "            xy=(p.get_x() + p.get_width() / 2, height),\n",
    "            xytext=(0, 3), # 3 points vertical offset\n",
    "            textcoords=\"offset points\",\n",
    "            ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "    return(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the scenarios to include in the bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"All_treated\",\"None_treated\",\"Actual_treatment\",\n",
    "           \"High_benchmark\", \"Low_benchmark\", \"Lowest_weighted_mrs\", \n",
    "           \"Highest_weighted_mrs\", \"Least_mrs5_6\", \n",
    "           \"Most_mrs5_6\", \"Lowest_weighted_mrs_and_least_mrs5_6\", \n",
    "           \"Highest_weighted_mrs_and_most_mrs5_6\", \n",
    "           \"Weighted_mrs_threshold_improvement\", \n",
    "           \"Weighted_mrs_threshold_improvement_and_least_mrs5_6\", \"Least_mrs6\"]\n",
    "\n",
    "xticks = [dict_scenario_information[f\"{col_name}_full_name\"] for col_name in columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 (of 4) to ask of the results seen in notebook 210. \n",
    "## Which type of patients have indifferent outcomes with treatment?\n",
    "Where's the break even point?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of patients that have same weighted mRS with or without treatment.\n",
    "Calculate the number of patients that have same likelihood of bad outcome (mRS5+) with or without treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_mrs_all_treated = df_weighted_mrs_per_scenario[\"All_treated\"]\n",
    "weighted_mrs_none_treated = df_weighted_mrs_per_scenario[\"None_treated\"]\n",
    "\n",
    "mask_indifferent_weighted_mrs = (\n",
    "                    weighted_mrs_all_treated == weighted_mrs_none_treated)\n",
    "\n",
    "proportion_mrs5_6_all_treated = y_outcome_probs_all_treated[:,5:].sum(axis=1)\n",
    "proportion_mrs5_6_not_treated = y_outcome_probs_none_treated[:,5:].sum(axis=1)\n",
    "\n",
    "mask_indifferent_proportion_mrs5_6 = (\n",
    "    proportion_mrs5_6_all_treated == proportion_mrs5_6_not_treated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 209 patients that have an indifferent weighted mRS due to treatment, 100% of them also have an indifferent likelihood of mRS5+ (209 patients)\n"
     ]
    }
   ],
   "source": [
    "patient_in_both = (\n",
    "    mask_indifferent_weighted_mrs == mask_indifferent_proportion_mrs5_6)\n",
    "percent_matched = (patient_in_both.sum()/mask_indifferent_weighted_mrs.shape[0] * 100)\n",
    "print(f\"Of the {mask_indifferent_weighted_mrs.sum()} patients that have an \"\n",
    "      f\"indifferent weighted mRS due to treatment\"\n",
    "      f\", {round(percent_matched)}% of them also have an indifferent \"\n",
    "      f\"likelihood of mRS5+ ({mask_indifferent_proportion_mrs5_6.sum()} patients)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As they are the same patient subgroup, the followig results are for the same patient subgroup.\n",
    "\n",
    "Describe the patient characteristics that have indifferent outcome based on treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stroke_severity</th>\n",
       "      <th>afib_anticoagulant</th>\n",
       "      <th>prior_disability</th>\n",
       "      <th>onset_during_sleep</th>\n",
       "      <th>onset_to_thrombolysis_time</th>\n",
       "      <th>discharge_disability</th>\n",
       "      <th>age</th>\n",
       "      <th>onset_to_arrival_time</th>\n",
       "      <th>precise_onset_known</th>\n",
       "      <th>arrival_to_scan_time</th>\n",
       "      <th>...</th>\n",
       "      <th>team_Whiston Hospital HASU</th>\n",
       "      <th>team_William Harvey Hospital</th>\n",
       "      <th>team_Wirral Arrowe Park Hospital</th>\n",
       "      <th>team_Withybush General Hospital</th>\n",
       "      <th>team_Worcestershire Royal Hospital</th>\n",
       "      <th>team_Worthing Hospital</th>\n",
       "      <th>team_Wycombe General Hospital</th>\n",
       "      <th>team_Yeovil District Hospital</th>\n",
       "      <th>team_York Hospital</th>\n",
       "      <th>team_Ysbyty Gwynedd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.770335</td>\n",
       "      <td>0.047847</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>2.306220</td>\n",
       "      <td>72.476077</td>\n",
       "      <td>16.736842</td>\n",
       "      <td>0.784689</td>\n",
       "      <td>11.483254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.014354</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.198082</td>\n",
       "      <td>0.213955</td>\n",
       "      <td>1.108571</td>\n",
       "      <td>0.097588</td>\n",
       "      <td>67.417332</td>\n",
       "      <td>1.922041</td>\n",
       "      <td>12.686092</td>\n",
       "      <td>11.989684</td>\n",
       "      <td>0.412025</td>\n",
       "      <td>8.231095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069171</td>\n",
       "      <td>0.119231</td>\n",
       "      <td>0.069171</td>\n",
       "      <td>0.069171</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stroke_severity  afib_anticoagulant  prior_disability  \\\n",
       "count       209.000000          209.000000        209.000000   \n",
       "mean          9.770335            0.047847          0.555024   \n",
       "std           7.198082            0.213955          1.108571   \n",
       "min           0.000000            0.000000          0.000000   \n",
       "25%           4.000000            0.000000          0.000000   \n",
       "50%           8.000000            0.000000          0.000000   \n",
       "75%          15.000000            0.000000          1.000000   \n",
       "max          30.000000            1.000000          5.000000   \n",
       "\n",
       "       onset_during_sleep  onset_to_thrombolysis_time  discharge_disability  \\\n",
       "count          209.000000                  209.000000            209.000000   \n",
       "mean             0.009569                    0.473684              2.306220   \n",
       "std              0.097588                   67.417332              1.922041   \n",
       "min              0.000000                 -100.000000              0.000000   \n",
       "25%              0.000000                 -100.000000              1.000000   \n",
       "50%              0.000000                   41.000000              2.000000   \n",
       "75%              0.000000                   50.000000              4.000000   \n",
       "max              1.000000                   55.000000              6.000000   \n",
       "\n",
       "              age  onset_to_arrival_time  precise_onset_known  \\\n",
       "count  209.000000             209.000000           209.000000   \n",
       "mean    72.476077              16.736842             0.784689   \n",
       "std     12.686092              11.989684             0.412025   \n",
       "min     37.500000               1.000000             0.000000   \n",
       "25%     67.500000               6.000000             1.000000   \n",
       "50%     72.500000              15.000000             1.000000   \n",
       "75%     82.500000              25.000000             1.000000   \n",
       "max     92.500000              48.000000             1.000000   \n",
       "\n",
       "       arrival_to_scan_time  ...  team_Whiston Hospital HASU  \\\n",
       "count            209.000000  ...                  209.000000   \n",
       "mean              11.483254  ...                    0.019139   \n",
       "std                8.231095  ...                    0.137342   \n",
       "min                1.000000  ...                    0.000000   \n",
       "25%                5.000000  ...                    0.000000   \n",
       "50%               10.000000  ...                    0.000000   \n",
       "75%               16.000000  ...                    0.000000   \n",
       "max               51.000000  ...                    1.000000   \n",
       "\n",
       "       team_William Harvey Hospital  team_Wirral Arrowe Park Hospital  \\\n",
       "count                         209.0                        209.000000   \n",
       "mean                            0.0                          0.004785   \n",
       "std                             0.0                          0.069171   \n",
       "min                             0.0                          0.000000   \n",
       "25%                             0.0                          0.000000   \n",
       "50%                             0.0                          0.000000   \n",
       "75%                             0.0                          0.000000   \n",
       "max                             0.0                          1.000000   \n",
       "\n",
       "       team_Withybush General Hospital  team_Worcestershire Royal Hospital  \\\n",
       "count                            209.0                               209.0   \n",
       "mean                               0.0                                 0.0   \n",
       "std                                0.0                                 0.0   \n",
       "min                                0.0                                 0.0   \n",
       "25%                                0.0                                 0.0   \n",
       "50%                                0.0                                 0.0   \n",
       "75%                                0.0                                 0.0   \n",
       "max                                0.0                                 0.0   \n",
       "\n",
       "       team_Worthing Hospital  team_Wycombe General Hospital  \\\n",
       "count              209.000000                     209.000000   \n",
       "mean                 0.004785                       0.014354   \n",
       "std                  0.069171                       0.119231   \n",
       "min                  0.000000                       0.000000   \n",
       "25%                  0.000000                       0.000000   \n",
       "50%                  0.000000                       0.000000   \n",
       "75%                  0.000000                       0.000000   \n",
       "max                  1.000000                       1.000000   \n",
       "\n",
       "       team_Yeovil District Hospital  team_York Hospital  team_Ysbyty Gwynedd  \n",
       "count                     209.000000          209.000000                209.0  \n",
       "mean                        0.004785            0.004785                  0.0  \n",
       "std                         0.069171            0.069171                  0.0  \n",
       "min                         0.000000            0.000000                  0.0  \n",
       "25%                         0.000000            0.000000                  0.0  \n",
       "50%                         0.000000            0.000000                  0.0  \n",
       "75%                         0.000000            0.000000                  0.0  \n",
       "max                         1.000000            1.000000                  0.0  \n",
       "\n",
       "[8 rows x 129 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[mask_indifferent_weighted_mrs.values].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stroke_severity</th>\n",
       "      <th>afib_anticoagulant</th>\n",
       "      <th>prior_disability</th>\n",
       "      <th>onset_during_sleep</th>\n",
       "      <th>onset_to_thrombolysis_time</th>\n",
       "      <th>discharge_disability</th>\n",
       "      <th>age</th>\n",
       "      <th>onset_to_arrival_time</th>\n",
       "      <th>precise_onset_known</th>\n",
       "      <th>arrival_to_scan_time</th>\n",
       "      <th>...</th>\n",
       "      <th>team_Whiston Hospital HASU</th>\n",
       "      <th>team_William Harvey Hospital</th>\n",
       "      <th>team_Wirral Arrowe Park Hospital</th>\n",
       "      <th>team_Withybush General Hospital</th>\n",
       "      <th>team_Worcestershire Royal Hospital</th>\n",
       "      <th>team_Worthing Hospital</th>\n",
       "      <th>team_Wycombe General Hospital</th>\n",
       "      <th>team_Yeovil District Hospital</th>\n",
       "      <th>team_York Hospital</th>\n",
       "      <th>team_Ysbyty Gwynedd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.770335</td>\n",
       "      <td>0.047847</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>2.306220</td>\n",
       "      <td>72.476077</td>\n",
       "      <td>16.736842</td>\n",
       "      <td>0.784689</td>\n",
       "      <td>11.483254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.014354</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.198082</td>\n",
       "      <td>0.213955</td>\n",
       "      <td>1.108571</td>\n",
       "      <td>0.097588</td>\n",
       "      <td>67.417332</td>\n",
       "      <td>1.922041</td>\n",
       "      <td>12.686092</td>\n",
       "      <td>11.989684</td>\n",
       "      <td>0.412025</td>\n",
       "      <td>8.231095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069171</td>\n",
       "      <td>0.119231</td>\n",
       "      <td>0.069171</td>\n",
       "      <td>0.069171</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stroke_severity  afib_anticoagulant  prior_disability  \\\n",
       "count       209.000000          209.000000        209.000000   \n",
       "mean          9.770335            0.047847          0.555024   \n",
       "std           7.198082            0.213955          1.108571   \n",
       "min           0.000000            0.000000          0.000000   \n",
       "25%           4.000000            0.000000          0.000000   \n",
       "50%           8.000000            0.000000          0.000000   \n",
       "75%          15.000000            0.000000          1.000000   \n",
       "max          30.000000            1.000000          5.000000   \n",
       "\n",
       "       onset_during_sleep  onset_to_thrombolysis_time  discharge_disability  \\\n",
       "count          209.000000                  209.000000            209.000000   \n",
       "mean             0.009569                    0.473684              2.306220   \n",
       "std              0.097588                   67.417332              1.922041   \n",
       "min              0.000000                 -100.000000              0.000000   \n",
       "25%              0.000000                 -100.000000              1.000000   \n",
       "50%              0.000000                   41.000000              2.000000   \n",
       "75%              0.000000                   50.000000              4.000000   \n",
       "max              1.000000                   55.000000              6.000000   \n",
       "\n",
       "              age  onset_to_arrival_time  precise_onset_known  \\\n",
       "count  209.000000             209.000000           209.000000   \n",
       "mean    72.476077              16.736842             0.784689   \n",
       "std     12.686092              11.989684             0.412025   \n",
       "min     37.500000               1.000000             0.000000   \n",
       "25%     67.500000               6.000000             1.000000   \n",
       "50%     72.500000              15.000000             1.000000   \n",
       "75%     82.500000              25.000000             1.000000   \n",
       "max     92.500000              48.000000             1.000000   \n",
       "\n",
       "       arrival_to_scan_time  ...  team_Whiston Hospital HASU  \\\n",
       "count            209.000000  ...                  209.000000   \n",
       "mean              11.483254  ...                    0.019139   \n",
       "std                8.231095  ...                    0.137342   \n",
       "min                1.000000  ...                    0.000000   \n",
       "25%                5.000000  ...                    0.000000   \n",
       "50%               10.000000  ...                    0.000000   \n",
       "75%               16.000000  ...                    0.000000   \n",
       "max               51.000000  ...                    1.000000   \n",
       "\n",
       "       team_William Harvey Hospital  team_Wirral Arrowe Park Hospital  \\\n",
       "count                         209.0                        209.000000   \n",
       "mean                            0.0                          0.004785   \n",
       "std                             0.0                          0.069171   \n",
       "min                             0.0                          0.000000   \n",
       "25%                             0.0                          0.000000   \n",
       "50%                             0.0                          0.000000   \n",
       "75%                             0.0                          0.000000   \n",
       "max                             0.0                          1.000000   \n",
       "\n",
       "       team_Withybush General Hospital  team_Worcestershire Royal Hospital  \\\n",
       "count                            209.0                               209.0   \n",
       "mean                               0.0                                 0.0   \n",
       "std                                0.0                                 0.0   \n",
       "min                                0.0                                 0.0   \n",
       "25%                                0.0                                 0.0   \n",
       "50%                                0.0                                 0.0   \n",
       "75%                                0.0                                 0.0   \n",
       "max                                0.0                                 0.0   \n",
       "\n",
       "       team_Worthing Hospital  team_Wycombe General Hospital  \\\n",
       "count              209.000000                     209.000000   \n",
       "mean                 0.004785                       0.014354   \n",
       "std                  0.069171                       0.119231   \n",
       "min                  0.000000                       0.000000   \n",
       "25%                  0.000000                       0.000000   \n",
       "50%                  0.000000                       0.000000   \n",
       "75%                  0.000000                       0.000000   \n",
       "max                  1.000000                       1.000000   \n",
       "\n",
       "       team_Yeovil District Hospital  team_York Hospital  team_Ysbyty Gwynedd  \n",
       "count                     209.000000          209.000000                209.0  \n",
       "mean                        0.004785            0.004785                  0.0  \n",
       "std                         0.069171            0.069171                  0.0  \n",
       "min                         0.000000            0.000000                  0.0  \n",
       "25%                         0.000000            0.000000                  0.0  \n",
       "50%                         0.000000            0.000000                  0.0  \n",
       "75%                         0.000000            0.000000                  0.0  \n",
       "max                         1.000000            1.000000                  0.0  \n",
       "\n",
       "[8 rows x 129 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[mask_indifferent_proportion_mrs5_6].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('sam10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f85b883bff9a8a9f39576b94acbdf6672b3dc17c35647e7395f81e785740a4b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
